{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYPATH = '../PROD/'\n",
    "[f for f in listdir(MYPATH) if (isfile(join(MYPATH, f))) & (f != 'tmp')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate production files into python data array\n",
    "onlyfiles = [f for f in listdir(MYPATH) if (isfile(join(MYPATH, f))) & (f != 'tmp')]\n",
    "data = []\n",
    "for file in onlyfiles:\n",
    "    with open(join(MYPATH,file), 'r') as f:\n",
    "        data.extend(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the trailing \"\\n\" from each line\n",
    "data = map(lambda x: x.rstrip(), data)\n",
    "\n",
    "# each element of 'data' is an individual JSON object.\n",
    "# i want to convert it into an *array* of JSON objects\n",
    "# which, in and of itself, is one large JSON object\n",
    "# basically... add square brackets to the beginning\n",
    "# and end, and have all the individual business JSON objects\n",
    "# separated by a comma\n",
    "data_json_str = \"[\" + ''.join(data)\n",
    "data_json_str = data_json_str[:-1] + \"]\"\n",
    "\n",
    "# now, load it into pandas\n",
    "data_df = pd.read_json(data_json_str)\n",
    "\n",
    "# Parse the properties json content to df new columns\n",
    "new_col_names=['agent_id', 'what', 'class_name', 'feat_name', 'stat']\n",
    "for col in new_col_names:\n",
    "    data_df[col] = data_df.loc[:,'properties'].apply(lambda x: x[col] if col in x.keys() else '')\n",
    "\n",
    "data_df['id'] = data_df.apply(lambda x: x['what'] + '_' + x['class_name'] + x['feat_name'] + '_' + x['stat'], axis=1)\n",
    "\n",
    "#drop duplicate lines\n",
    "df = data_df.drop(['properties', 'tags'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_info(df):\n",
    "    print('Number of data sources (agents) : {}'.format(len(df.agent_id.unique())))\n",
    "    print('Name of agents : {} \\n'.format([x for x in df.agent_id.unique()]))\n",
    "    for agent_name in df.agent_id.unique():\n",
    "        df_agent = df[df.agent_id == agent_name]\n",
    "        print('-- {} --'.format(agent_name))\n",
    "        print('Number of time series : {}'.format(len(df_agent.id.unique())))\n",
    "        print('Number of feature time series analytics = {}'.format(len(df_agent[df_agent.feat_name != ''].id.unique())))\n",
    "        print('Number of prediction time series analytics = {}'.format(len(df_agent[['prediction' in x for x in df_agent.what.values]].id.unique())))\n",
    "        print('Number of label time series analytics = {}'.format(len(df_agent[[('prediction' not in x)&('feature' not in x) for x in df_agent.what.values]].id.unique())))\n",
    "        print('Start date : {}'.format(df_agent.timestamp.min()))\n",
    "        print('End date : {}\\n'.format(df_agent.timestamp.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT A DATA SOURCE TO ANALYZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to analyze a specific dataset\n",
    "df = df[df['agent_id'] == 'MNIST_Multiclass_wrong_inputs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS FREQUENCY DRIFT GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = df[df['what'] == 'prediction_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_names = df_prediction['class_name'].unique()\n",
    "\n",
    "x = df_prediction['timestamp'].unique()\n",
    "y = np.vstack([df_prediction[df_prediction.class_name == class_name]['value'].values for class_name in classes_names])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "_ = plt.stackplot(x, y, labels = classes_names)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCH SIZE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_batchsize=df[df['what'] == 'prediction_count'].groupby('timestamp')['value'].sum()\n",
    "df_batchsize.plot(x='timestamp', figsize = (15,2), title='batch_size')\n",
    "print('BATCH SIZE GRAPH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE METRICS DISTRIBUTION GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in df['id'].unique()[1000:1050]:\n",
    "    if 'feature' in metric:\n",
    "        df_=df[df['id'] == metric]\n",
    "        df_.plot(x='timestamp', y='value', figsize = (15,2), title=str(metric))\n",
    "print('INPUT METRIX GRAPHS(first 50 metrix) : {} graphs'.format(sum(['feature' in x for x in df['id'].unique()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION METRICS DISTRIBUTION GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in df['id'].unique()[:]:\n",
    "    if 'prediction' in metric:\n",
    "        df_=df[df['id'] == metric]\n",
    "        df_.plot(x='timestamp', y='value', figsize = (15,2), title=str(metric))\n",
    "print('OUTPUT METRIX GRAPHS (all metrix) : {} graphs'.format(sum(['prediction' in x for x in df['id'].unique()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL METRICS DISTRIBUTION GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in df['id'].unique()[:]:\n",
    "    if ('prediction' not in metric) & ('feature' not in metric):\n",
    "        df_=df[df['id'] == metric]\n",
    "        df_.plot(x='timestamp', y='value', figsize = (15,2), title=str(metric))\n",
    "print('LABELS METRIX GRAPHS (all metrix) : {} graphs'.format(sum([('prediction' not in x) & ('feature' not in x) for x in df['id'].unique()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
